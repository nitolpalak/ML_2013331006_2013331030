{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import glob\n",
    "import csv\n",
    "import operator\n",
    "from sklearn import svm\n",
    "\n",
    "\n",
    "# from keras.models import Sequential\n",
    "# from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "path ='C:\\2012' # use your path\n",
    "allFiles = glob.glob(path+\"/*.csv\")\n",
    "mlist=[]\n",
    "dt=[]\n",
    "cp=[]\n",
    "dat=0\n",
    "# print(allFiles)\n",
    "for f in allFiles:\n",
    "    with open(f, 'r') as f1:\n",
    "        reader = csv.reader(f1)\n",
    "        dat=dat+1\n",
    "       # print(dat)\n",
    "        for o in reader:\n",
    "            o[1]=dat\n",
    "            mlist.append(o)\n",
    "path ='2013' # use your path\n",
    "allFiles = glob.glob(path + \"/*.csv\")\n",
    "for f in allFiles:\n",
    "    with open(f, 'r') as f1:\n",
    "        reader = csv.reader(f1)\n",
    "        dat=dat+1\n",
    "       # print(dat)\n",
    "        for o in reader:\n",
    "            o[1]=dat\n",
    "            mlist.append(o)\n",
    "path ='2014' # use your path\n",
    "allFiles = glob.glob(path + \"/*.csv\")\n",
    "for f in allFiles:\n",
    "    with open(f, 'r') as f1:\n",
    "        reader = csv.reader(f1)\n",
    "        dat=dat+1\n",
    "       # print(dat)\n",
    "        for o in reader:\n",
    "            o[1]=dat            \n",
    "            mlist.append(o)\n",
    "path ='2015' # use your path\n",
    "allFiles = glob.glob(path + \"/*.csv\")\n",
    "# print(allFiles)\n",
    "for f in allFiles:\n",
    "    with open(f, 'r') as f1:\n",
    "        reader = csv.reader(f1)\n",
    "        dat=dat+1\n",
    "      #  print(dat)\n",
    "        for o in reader:\n",
    "            o[1]=dat \n",
    "            mlist.append(o)\n",
    "sorlist=sorted(mlist, key=operator.itemgetter(0,1), reverse=False)\n",
    "na=np.array(sorlist)\n",
    "# print(na)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainx=[]\n",
    "trainy=[]\n",
    "\n",
    "x=0\n",
    "y=na[0][0]\n",
    "list1=[]\n",
    "list2=[]\n",
    "for i in na:    \n",
    "    if(y!=i[0]):\n",
    "       # print(list2)\n",
    "        y=i[0]\n",
    "        trainx.append(list1)\n",
    "        trainy.append(list2)\n",
    "        list1=[]\n",
    "        list2=[]\n",
    "    try: \n",
    "        kx=[]\n",
    "        kx.append(float(i[1]))\n",
    "        kx.append(float(i[5]))\n",
    "        kx.append(float(i[6]))\n",
    "        list1.append(kx)\n",
    "        list2.append(float(i[5]))\n",
    "    except:\n",
    "        print(\"\")\n",
    "\n",
    "x_train = trainx[:300]\n",
    "y_train = trainy[:300]\n",
    "x_test = trainx[301:]\n",
    "y_test = trainy[301:]\n",
    "    \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def Result(result):\n",
    "        acc = 0\n",
    "        for i in range(0,len(result)):\n",
    "            acc=acc+(result[i]-trainy[k][i])**2\n",
    "        acc=acc/len(result)\n",
    "        acc=acc**(1/2.0)\n",
    "        print(1-acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "reg = LinearRegression()\n",
    "\n",
    "for k in range(0,1):\n",
    "    reg.fit(np.array(trainx[k][0:400]),np.array(trainy[k][1:401]))\n",
    "    result = reg.predict(np.array(trainx[k][0:400]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.491202493389\n"
     ]
    }
   ],
   "source": [
    "Result(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  RANSAC Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import RANSACRegressor\n",
    "reg = RANSACRegressor()\n",
    "for k in range(0,1):\n",
    "    reg.fit(np.array(trainx[k][0:400]),np.array(trainy[k][1:401]))\n",
    "    result = reg.predict(np.array(trainx[k][0:400]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.750220536412\n"
     ]
    }
   ],
   "source": [
    "Result(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "reg = RandomForestRegressor()\n",
    "for k in range(0,1):\n",
    "    reg.fit(np.array(trainx[k][0:400]),np.array(trainy[k][1:401]))\n",
    "    result = reg.predict(np.array(trainx[k][0:400]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.348516884332\n"
     ]
    }
   ],
   "source": [
    "Result(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ElasticNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import ElasticNet\n",
    "reg = ElasticNet()\n",
    "for k in range(0,1):\n",
    "    reg.fit(np.array(trainx[k][0:400]),np.array(trainy[k][1:401]))\n",
    "    result = reg.predict(np.array(trainx[k][0:400]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.462535764483\n"
     ]
    }
   ],
   "source": [
    "Result(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lasso LARS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LassoLars\n",
    "sgd = LassoLars()\n",
    "sgd.fit(np.array(trainx[k][0:400]),np.array(trainy[k][1:401]))\n",
    "result = reg.predict(np.array(trainx[k][0:400]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.462535764483\n"
     ]
    }
   ],
   "source": [
    "Result(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "reg = Ridge()\n",
    "reg.fit(np.array(trainx[k][0:400]),np.array(trainy[k][1:401]))\n",
    "result = reg.predict(np.array(trainx[k][0:400]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.490928514616\n"
     ]
    }
   ],
   "source": [
    "Result(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "reg = Lasso(alpha=0.1)\n",
    "reg.fit(np.array(trainx[k][0:400]),np.array(trainy[k][1:401]))\n",
    "result = reg.predict(np.array(trainx[k][0:400]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.462364699721\n"
     ]
    }
   ],
   "source": [
    "Result(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bayesian Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import BayesianRidge\n",
    "reg = BayesianRidge()\n",
    "reg.fit(np.array(trainx[k][0:400]),np.array(trainy[k][1:401]))\n",
    "result = reg.predict(np.array(trainx[k][0:400]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.46251748797\n"
     ]
    }
   ],
   "source": [
    "Result(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GBR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "reg = GradientBoostingRegressor()\n",
    "reg.fit(np.array(trainx[k][0:400]),np.array(trainy[k][1:401]))\n",
    "result = reg.predict(np.array(trainx[k][0:400]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.412078527663\n"
     ]
    }
   ],
   "source": [
    "Result(result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
